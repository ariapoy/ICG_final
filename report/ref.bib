@inproceedings{CVPR2016_Gatys_stcnn,
  title={Image style transfer using convolutional neural networks},
  author={Gatys, Leon A and Ecker, Alexander S and Bethge, Matthias},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2414--2423},
  year={2016}
}

@article{2020_Huang_sdf,
  title={Style is a Distribution of Features},
  author={Huang, Eddie and Gupta, Sahil},
  journal={arXiv preprint arXiv:2007.13010},
  year={2020}
}

@inproceedings{2017_Okawa_canny,
  title={Automatic pencil sketch generation by using canny edges},
  author={Okawa, Ryota and Yoshida, Hiromi and Iiguni, Youji},
  booktitle={2017 fifteenth IAPR international conference on machine vision applications (MVA)},
  pages={282--285},
  year={2017},
  organization={IEEE}
}

@inproceedings{2012_Lu_combine,
  title={Combining sketch and tone for pencil drawing production},
  author={Lu, Cewu and Xu, Li and Jia, Jiaya},
  booktitle={Proceedings of the symposium on non-photorealistic animation and rendering},
  pages={65--73},
  year={2012},
  organization={Citeseer}
}

@INPROCEEDINGS{2019CVPR_Li_img2pencil,  
  author={Li, Yijun and Fang, Chen and Hertzmann, Aaron and Shechtman, Eli and Yang, Ming-Hsuan},  
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},   
  title={Im2Pencil: Controllable Pencil Illustration From Photographs},   
  year={2019},  
  volume={},  
  number={},  
  pages={1525-1534},  
  doi={10.1109/CVPR.2019.00162}
}

@InProceedings{2017pmlr-arjovsky-wgan, 
  title = {{W}asserstein Generative Adversarial Networks}, 
  author = {Martin Arjovsky and Soumith Chintala and L{\'e}on Bottou}, 
  booktitle = {Proceedings of the 34th International Conference on Machine Learning}, pages = {214--223}, year = {2017}, 
  editor = {Precup, Doina and Teh, Yee Whye}, volume = {70}, series = {Proceedings of Machine Learning Research}, month = {06--11 Aug}, 
  publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v70/arjovsky17a/arjovsky17a.pdf}, url = { http://proceedings.mlr.press/v70/arjovsky17a.html }, 
  abstract = {We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to different distances between distributions.} 
}